{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNsn8jfwfvVllMNADO/U3Px",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dhruvnigam93/notebooks/blob/main/TabularEmbeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p92tAF8ELFov",
        "outputId": "761e4a47-e108-4501-8f8e-c5781ef90dca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "California Housing Dataset loaded:\n",
            "Number of samples: 20640\n",
            "Number of features: 8\n",
            "Features: ['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup', 'Latitude', 'Longitude']\n",
            "\n",
            "First few rows of the dataset:\n",
            "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
            "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
            "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
            "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
            "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
            "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
            "\n",
            "   Longitude  \n",
            "0    -122.23  \n",
            "1    -122.22  \n",
            "2    -122.24  \n",
            "3    -122.25  \n",
            "4    -122.25  \n",
            "\n",
            "Target variable statistics:\n",
            "count    20640.000000\n",
            "mean         2.068558\n",
            "std          1.153956\n",
            "min          0.149990\n",
            "25%          1.196000\n",
            "50%          1.797000\n",
            "75%          2.647250\n",
            "max          5.000010\n",
            "dtype: float64\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "import shap\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.inspection import permutation_importance\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Load the Boston Housing dataset\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "housing = fetch_california_housing()\n",
        "X = pd.DataFrame(housing.data, columns=housing.feature_names)\n",
        "y = housing.target\n",
        "\n",
        "print(\"California Housing Dataset loaded:\")\n",
        "print(f\"Number of samples: {X.shape[0]}\")\n",
        "print(f\"Number of features: {X.shape[1]}\")\n",
        "print(f\"Features: {housing.feature_names}\")\n",
        "print(\"\\nFirst few rows of the dataset:\")\n",
        "print(X.head())\n",
        "print(\"\\nTarget variable statistics:\")\n",
        "print(pd.Series(y).describe())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Convert back to DataFrame for easier handling\n",
        "X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
        "X_test_scaled_df = pd.DataFrame(X_test_scaled, columns=X_test.columns)\n",
        "\n",
        "# Train a Random Forest Regressor\n",
        "print(\"\\nTraining Random Forest model...\")\n",
        "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred = rf_model.predict(X_test_scaled)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Model Performance:\")\n",
        "print(f\"Mean Squared Error: {mse:.4f}\")\n",
        "print(f\"R² Score: {r2:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R8suYuowLONI",
        "outputId": "30c89503-7c11-47e9-cdaa-5b90a22ed356"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training Random Forest model...\n",
            "Model Performance:\n",
            "Mean Squared Error: 0.2552\n",
            "R² Score: 0.8053\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# 1. ShapCA Implementation\n",
        "print(\"\\nImplementing ShapCA (SHAP + PCA)...\")\n",
        "\n",
        "# Calculate SHAP values\n",
        "explainer = shap.TreeExplainer(rf_model)\n",
        "shap_values = explainer.shap_values(X_test_scaled_df)\n",
        "\n",
        "# Convert SHAP values to a DataFrame\n",
        "shap_df = pd.DataFrame(shap_values, columns=X_test_scaled_df.columns)\n",
        "\n",
        "# Apply PCA to SHAP values\n",
        "pca = PCA(n_components=2)\n",
        "shapca_embedding = pca.fit_transform(shap_df)\n",
        "\n",
        "# Visualize ShapCA embedding\n",
        "plt.figure(figsize=(10, 8))\n",
        "sc = plt.scatter(shapca_embedding[:, 0], shapca_embedding[:, 1], c=y_test, cmap='viridis', alpha=0.6)\n",
        "plt.colorbar(sc, label='House Price')\n",
        "plt.title('ShapCA: 2D Embedding of SHAP Values')\n",
        "plt.xlabel('ShapCA Component 1')\n",
        "plt.ylabel('ShapCA Component 2')\n",
        "plt.tight_layout()\n",
        "plt.savefig('shapca_embedding.png')\n",
        "plt.close()\n",
        "\n",
        "# Calculate explained variance ratio\n",
        "shapca_explained_variance = pca.explained_variance_ratio_\n",
        "print(f\"ShapCA explained variance ratio: {shapca_explained_variance}\")\n",
        "print(f\"Total explained variance: {sum(shapca_explained_variance):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IdvzlbFMLYt8",
        "outputId": "80a2fda7-a118-4d0f-b36f-df4726d3e0bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Implementing ShapCA (SHAP + PCA)...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 2. RFSNE Implementation (Random Forest + t-SNE)\n",
        "print(\"\\nImplementing RFSNE (Random Forest + t-SNE)...\")\n",
        "\n",
        "def compute_proximity_matrix(rf_model, X):\n",
        "    \"\"\"Compute proximity matrix from Random Forest model\"\"\"\n",
        "    # Get leaf indices for each sample in each tree\n",
        "    terminals = []\n",
        "    for tree in rf_model.estimators_:\n",
        "        terminals.append(tree.apply(X))\n",
        "\n",
        "    terminals = np.array(terminals)\n",
        "    n_samples = X.shape[0]\n",
        "    proximity_matrix = np.zeros((n_samples, n_samples))\n",
        "\n",
        "    # Count how many times each pair of samples end up in the same leaf\n",
        "    for i in range(n_samples):\n",
        "        for j in range(i, n_samples):\n",
        "            # Count how many times samples i and j are in the same terminal node\n",
        "            same_leaf = np.sum(terminals[:, i] == terminals[:, j])\n",
        "            proximity = same_leaf / len(rf_model.estimators_)\n",
        "            proximity_matrix[i, j] = proximity\n",
        "            proximity_matrix[j, i] = proximity  # Symmetrical\n",
        "\n",
        "    return proximity_matrix\n",
        "\n",
        "# Sample a subset of data for proximity calculation (for efficiency)\n",
        "sample_size = min(1000, X_test_scaled.shape[0])\n",
        "random_indices = np.random.choice(X_test_scaled.shape[0], sample_size, replace=False)\n",
        "X_sample = X_test_scaled[random_indices]\n",
        "y_sample = y_test[random_indices]\n",
        "\n",
        "# Compute proximity matrix\n",
        "print(\"Computing proximity matrix...\")\n",
        "proximity_matrix = compute_proximity_matrix(rf_model, X_sample)\n",
        "\n",
        "# Convert proximity to distance\n",
        "# Proximity of 1 means identical, 0 means completely different\n",
        "# For t-SNE, we need distance (1 - proximity)\n",
        "distance_matrix = 1 - proximity_matrix\n",
        "\n",
        "# Apply t-SNE to the distance matrix\n",
        "print(\"Applying t-SNE...\")\n",
        "tsne = TSNE(n_components=2, metric='precomputed', random_state=42)\n",
        "rfsne_embedding = tsne.fit_transform(distance_matrix)\n",
        "\n",
        "# Visualize RFSNE embedding\n",
        "plt.figure(figsize=(10, 8))\n",
        "sc = plt.scatter(rfsne_embedding[:, 0], rfsne_embedding[:, 1], c=y_sample, cmap='viridis', alpha=0.6)\n",
        "plt.colorbar(sc, label='House Price')\n",
        "plt.title('RFSNE: 2D Embedding using RF Proximity + t-SNE')\n",
        "plt.xlabel('RFSNE Component 1')\n",
        "plt.ylabel('RFSNE Component 2')\n",
        "plt.tight_layout()\n",
        "plt.savefig('rfsne_embedding.png')\n",
        "plt.close()\n",
        "\n"
      ],
      "metadata": {
        "id": "jUDd0zP2LiE4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Compare with standard dimensionality reduction techniques\n",
        "print(\"\\nComparing with standard dimensionality reduction techniques...\")\n",
        "\n",
        "# PCA on raw features\n",
        "pca_raw = PCA(n_components=2)\n",
        "pca_embedding = pca_raw.fit_transform(X_test_scaled)\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sc = plt.scatter(pca_embedding[:, 0], pca_embedding[:, 1], c=y_test, cmap='viridis', alpha=0.6)\n",
        "plt.colorbar(sc, label='House Price')\n",
        "plt.title('PCA: 2D Embedding of Raw Features')\n",
        "plt.xlabel('PCA Component 1')\n",
        "plt.ylabel('PCA Component 2')\n",
        "plt.tight_layout()\n",
        "plt.savefig('pca_embedding.png')\n",
        "plt.close()\n",
        "\n",
        "# t-SNE on raw features\n",
        "tsne_raw = TSNE(n_components=2, random_state=42)\n",
        "tsne_embedding = tsne_raw.fit_transform(X_test_scaled[:1000])  # Using a subset for efficiency\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sc = plt.scatter(tsne_embedding[:, 0], tsne_embedding[:, 1], c=y_test[:1000], cmap='viridis', alpha=0.6)\n",
        "plt.colorbar(sc, label='House Price')\n",
        "plt.title('t-SNE: 2D Embedding of Raw Features')\n",
        "plt.xlabel('t-SNE Component 1')\n",
        "plt.ylabel('t-SNE Component 2')\n",
        "plt.tight_layout()\n",
        "plt.savefig('tsne_embedding.png')\n",
        "plt.close()"
      ],
      "metadata": {
        "id": "VUOT4tC6Nqaf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Evaluate the quality of the embeddings\n",
        "# For this, we'll train a simple model on the 2D embeddings and see how well it predicts\n",
        "\n",
        "# Function to evaluate embedding quality\n",
        "def evaluate_embedding(embedding, y_true, name):\n",
        "    rf_eval = RandomForestRegressor(n_estimators=50, random_state=42)\n",
        "    X_train_embed, X_test_embed, y_train_embed, y_test_embed = train_test_split(\n",
        "        embedding, y_true, test_size=0.3, random_state=42)\n",
        "\n",
        "    rf_eval.fit(X_train_embed, y_train_embed)\n",
        "    y_pred_embed = rf_eval.predict(X_test_embed)\n",
        "\n",
        "    mse_embed = mean_squared_error(y_test_embed, y_pred_embed)\n",
        "    r2_embed = r2_score(y_test_embed, y_pred_embed)\n",
        "\n",
        "    return {\n",
        "        'name': name,\n",
        "        'mse': mse_embed,\n",
        "        'r2': r2_embed\n",
        "    }\n",
        "\n",
        "# Evaluate all embeddings\n",
        "embedding_results = []\n",
        "\n",
        "# ShapCA\n",
        "embedding_results.append(evaluate_embedding(shapca_embedding, y_test, 'ShapCA'))\n",
        "\n",
        "# RFSNE\n",
        "embedding_results.append(evaluate_embedding(rfsne_embedding, y_sample, 'RFSNE'))\n",
        "\n",
        "# PCA\n",
        "embedding_results.append(evaluate_embedding(pca_embedding, y_test, 'PCA'))\n",
        "\n",
        "# t-SNE\n",
        "embedding_results.append(evaluate_embedding(tsne_embedding, y_test[:1000], 't-SNE'))\n",
        "\n",
        "# Display results\n",
        "embedding_results_df = pd.DataFrame(embedding_results)\n",
        "print(\"\\nEmbedding Quality Comparison:\")\n",
        "print(embedding_results_df)\n",
        "\n",
        "# Plot embedding quality comparison\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "sns.barplot(x='name', y='mse', data=embedding_results_df)\n",
        "plt.title('MSE Comparison')\n",
        "plt.ylabel('Mean Squared Error (lower is better)')\n",
        "plt.xlabel('')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "sns.barplot(x='name', y='r2', data=embedding_results_df)\n",
        "plt.title('R² Comparison')\n",
        "plt.ylabel('R² Score (higher is better)')\n",
        "plt.xlabel('')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('embedding_quality_comparison.png')\n",
        "plt.close()\n"
      ],
      "metadata": {
        "id": "V3lHdeyPLqAL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Demonstration of how embeddings can be used for transfer learning\n",
        "print(\"\\nDemonstrating transfer learning with embeddings...\")\n",
        "\n",
        "# Let's create a synthetic task: predicting whether a house is in the top 25% of prices\n",
        "median_price = np.median(y)\n",
        "top_quartile_threshold = np.percentile(y, 75)\n",
        "y_binary = (y > top_quartile_threshold).astype(int)\n",
        "\n",
        "# Split again for the new task\n",
        "X_train_tl, X_test_tl, y_train_tl, y_test_tl = train_test_split(\n",
        "    X, y_binary, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a model on the original features\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "rf_orig = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_orig.fit(X_train_tl, y_train_tl)\n",
        "y_pred_orig = rf_orig.predict(X_test_tl)\n",
        "acc_orig = accuracy_score(y_test_tl, y_pred_orig)\n",
        "\n",
        "print(f\"\\nOriginal features classification accuracy: {acc_orig:.4f}\")\n",
        "print(\"\\nClassification Report (Original Features):\")\n",
        "print(classification_report(y_test_tl, y_pred_orig))\n",
        "\n",
        "# Now, let's use our embeddings for transfer learning\n",
        "\n",
        "# Generate ShapCA embeddings for the entire dataset\n",
        "# First, we need SHAP values for all data\n",
        "explainer_all = shap.TreeExplainer(rf_model)\n",
        "shap_values_all = explainer_all.shap_values(X)\n",
        "shap_df_all = pd.DataFrame(shap_values_all, columns=X.columns)\n",
        "\n",
        "# Apply PCA to get ShapCA embeddings\n",
        "pca_all = PCA(n_components=2)\n",
        "shapca_all = pca_all.fit_transform(shap_df_all)\n",
        "\n",
        "# Train a model on the ShapCA embeddings\n",
        "X_train_shapca, X_test_shapca, y_train_shapca, y_test_shapca = train_test_split(\n",
        "    shapca_all, y_binary, test_size=0.2, random_state=42)\n",
        "\n",
        "rf_shapca = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_shapca.fit(X_train_shapca, y_train_shapca)\n",
        "y_pred_shapca = rf_shapca.predict(X_test_shapca)\n",
        "acc_shapca = accuracy_score(y_test_shapca, y_pred_shapca)\n",
        "\n",
        "print(f\"\\nShapCA embeddings classification accuracy: {acc_shapca:.4f}\")\n",
        "print(\"\\nClassification Report (ShapCA Embeddings):\")\n",
        "print(classification_report(y_test_shapca, y_pred_shapca))\n",
        "\n",
        "# Conclusion\n",
        "print(\"\\n=== Conclusion ===\")\n",
        "print(\"We've implemented and compared two embedding techniques for tabular data:\")\n",
        "print(\"1. ShapCA: Combining SHAP values with PCA\")\n",
        "print(\"2. RFSNE: Using Random Forest proximity with t-SNE\")\n",
        "print(\"\\nBoth techniques demonstrated the ability to create meaningful embeddings that:\")\n",
        "print(\"- Transform features into a unified space\")\n",
        "print(\"- Provide context-aware, motivated compression\")\n",
        "print(\"- Capture relationships relevant to the prediction task\")\n",
        "print(\"\\nThese embeddings can be visualized and used for transfer learning tasks.\")"
      ],
      "metadata": {
        "id": "MSxdf5nSLxl_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}